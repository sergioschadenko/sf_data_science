{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#импорт библиотек\n",
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import seaborn as sns #для визуализации\n",
    "\n",
    "from sklearn import linear_model #линейные модели\n",
    "from sklearn import ensemble #ансамбли\n",
    "from sklearn import metrics #метрики\n",
    "from sklearn.model_selection import train_test_split #сплитование выборки\n",
    "from sklearn.model_selection import cross_val_score #кросс-валидация\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV #оптимизация GridSearch\n",
    "from sklearn.model_selection import RandomizedSearchCV #оптимизация RandomSearch\n",
    "import hyperopt #оптимизация hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials #инструменты для оптимизации hyperopt\n",
    "import optuna #оптимизация optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/molecules.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#проверяем данные на сбалансированность\n",
    "sns.countplot(data=data, x='Activity');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные достаточно сбалансированы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделяем данные на матрицу наблюдений и вектор ответов\n",
    "X = data.drop(['Activity'], axis=1)\n",
    "y = data['Activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделяем выборку на тренировочную и тестовую\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1, test_size = 0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оптимизация логистической регрессии"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем базовую модель и смотрим ее метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тестовом наборе: 0.76\n",
      "f1_score на тестовом наборе: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#создаем объект класса логистическая регрессия\n",
    "log_reg = linear_model.LogisticRegression(max_iter=50)\n",
    "#обучаем модель, минимизируя logloss\n",
    "log_reg.fit(X_train, y_train)\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(log_reg.score(X_test, y_test)))\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществляем оптимизацию модели с помощью класса Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.19 s\n",
      "Wall time: 1min 42s\n",
      "accuracy на тестовом наборе: 0.76\n",
      "f1_score на тестовом наборе: 0.78\n",
      "Наилучшие значения гиперпараметров: {'C': 0.7, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "#определим сетку гиперпараметров\n",
    "param_grid = {'penalty': ['l1', 'l2'], #тип регуляризации\n",
    "              'solver': ['liblinear', 'saga'], #алгоритм оптимизации\n",
    "              'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}, #уровень силы регурялизации\n",
    "\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=42, #генератор случайных чисел\n",
    "        max_iter=50 #количество итераций на сходимость\n",
    "    ), \n",
    "    param_grid=param_grid,\n",
    "    cv=5, #количество фолдов в кросс-валидации\n",
    "    n_jobs = -1\n",
    ")  \n",
    "\n",
    "%time grid_search_1.fit(X_train, y_train) \n",
    "y_test_pred = grid_search_1.predict(X_test) #делаем предсказание на тестовой выборке\n",
    "\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search_1.score(X_test, y_test)))\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_1.best_params_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomized Search**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществляем оптимизацию модели с помощью класса Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 750 ms\n",
      "Wall time: 37 s\n",
      "accuracy на тестовом наборе: 0.78\n",
      "f1_score на тестовом наборе: 0.80\n",
      "Наилучшие значения гиперпараметров: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_distributions = {'penalty': ['l1', 'l2'], #тип регуляризации\n",
    "                       'solver': ['liblinear', 'saga'], #алгоритм оптимизации\n",
    "                       'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}, #уровень силы регурялизации\n",
    "            \n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=42,\n",
    "        max_iter=50 #количество итераций на сходимость\n",
    "        ), \n",
    "    param_distributions=param_distributions, \n",
    "    cv=5, #количество фолдов в кросс-валидации\n",
    "    n_iter = 10, #количество комбинаций на расчёт\n",
    "    n_jobs = -1\n",
    ")  \n",
    "\n",
    "%time random_search.fit(X_train, y_train)\n",
    "y_test_pred = random_search.predict(X_test) #делаем предсказание на тестовой выборке\n",
    "\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(random_search.score(X_test, y_test)))\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search.best_params_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperopt**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществляем оптимизацию модели с помощью класса Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#зададим пространство поиска гиперпараметров\n",
    "space = {'penalty': hp.choice('penalty', ['l1', 'l2']), #тип регуляризации\n",
    "         'solver': hp.choice('solver', ['liblinear', 'saga']), #алгоритм оптимизации\n",
    "         'C': hp.quniform('C', 0.2, 0.8, 0.01)} #уровень силы регурялизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#напишем функцию поиска гиперпараметров\n",
    "def hyperopt_lr(params, cv=5, X=X_train, y=y_train, random_state=42):\n",
    "    #функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'penalty': (params['penalty']), \n",
    "              'solver': (params['solver']),\n",
    "              'C': float(params['C'])\n",
    "              }\n",
    "  \n",
    "    #используем эту комбинацию для построения модели\n",
    "    model = linear_model.LogisticRegression(**params, \n",
    "                                            random_state=42,\n",
    "                                            max_iter=50) #количество итераций на сходимость\n",
    "\n",
    "    #обучаем модель с помощью кросс-валидации\n",
    "    model.fit(X, y)\n",
    "    score = cross_val_score(model, X, y, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    #метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:07<01:11,  7.98s/trial, best loss: -0.7800375021534195]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:25<00:52,  7.50s/trial, best loss: -0.7854845146076939]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:40<00:34,  6.86s/trial, best loss: -0.7876014805021191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:49<00:30,  7.71s/trial, best loss: -0.7876014805021191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:05<00:05,  5.68s/trial, best loss: -0.7883899088765386]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:18<00:00,  7.84s/trial, best loss: -0.7883899088765386]\n",
      "Наилучшие значения гиперпараметров {'C': 0.7000000000000001, 'penalty': 0, 'solver': 0}\n",
      "CPU times: total: 21.7 s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# начинаем подбор гиперпараметров\n",
    "\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best=fmin(hyperopt_lr, # наша функция \n",
    "          space=space, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=10, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.default_rng(random_state)# фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на обучающем наборе: 0.86\n",
      "accuracy на тестовом наборе: 0.76\n",
      "f1_score на тестовом наборе: 0.78\n"
     ]
    }
   ],
   "source": [
    "#рассчитаем точность для тестовой выборки, задав наилучшие параметры\n",
    "model = linear_model.LogisticRegression(\n",
    "    random_state=42, \n",
    "    penalty='l1',\n",
    "    solver='liblinear',\n",
    "    C=0.7000000000000001\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optuna**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществляем оптимизацию модели с помощью класса Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#напишем функцию для поиска гиперпараметров\n",
    "def optuna_lr(trial):\n",
    "  #задаем пространства поиска гиперпараметров\n",
    "  penalty = trial.suggest_categorical('penalty', ['l1', 'l2']) #тип регуляризации\n",
    "  solver = trial.suggest_categorical('solver', ['liblinear', 'saga']) #алгоритм оптимизации\n",
    "  C = trial.suggest_float('C', 0.2, 8, step=0.01) #уровень силы регурялизации\n",
    "\n",
    "  #создаем модель\n",
    "  model = linear_model.LogisticRegression(penalty=penalty,\n",
    "                                          solver=solver,\n",
    "                                          C=C,\n",
    "                                          random_state=42,\n",
    "                                          max_iter=50)\n",
    "  #обучаем модель\n",
    "  model.fit(X_train, y_train)\n",
    "  score = cross_val_score(model, X, y, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-20 22:08:59,859]\u001b[0m A new study created in memory with name: LogisticRegression\u001b[0m\n",
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-20 22:09:21,793]\u001b[0m Trial 0 finished with value: 0.777830514645634 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 6.3500000000000005}. Best is trial 0 with value: 0.777830514645634.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:09:36,082]\u001b[0m Trial 1 finished with value: 0.7657276668086463 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 2.79}. Best is trial 0 with value: 0.777830514645634.\u001b[0m\n",
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-20 22:10:03,094]\u001b[0m Trial 2 finished with value: 0.7792004586324458 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 3.14}. Best is trial 2 with value: 0.7792004586324458.\u001b[0m\n",
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-20 22:10:17,238]\u001b[0m Trial 3 finished with value: 0.7780895179467854 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 5.75}. Best is trial 2 with value: 0.7792004586324458.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:10:40,376]\u001b[0m Trial 4 finished with value: 0.7583337960879379 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 6.86}. Best is trial 2 with value: 0.7792004586324458.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:10:55,249]\u001b[0m Trial 5 finished with value: 0.7647846870742566 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 3.1300000000000003}. Best is trial 2 with value: 0.7792004586324458.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:11:00,526]\u001b[0m Trial 6 finished with value: 0.7627408302724121 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 3.74}. Best is trial 2 with value: 0.7792004586324458.\u001b[0m\n",
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-20 22:11:25,039]\u001b[0m Trial 7 finished with value: 0.777830514645634 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 6.41}. Best is trial 2 with value: 0.7792004586324458.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:11:38,117]\u001b[0m Trial 8 finished with value: 0.762232070980539 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 3.81}. Best is trial 2 with value: 0.7792004586324458.\u001b[0m\n",
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-20 22:11:47,815]\u001b[0m Trial 9 finished with value: 0.7781952711617064 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 4.57}. Best is trial 2 with value: 0.7792004586324458.\u001b[0m\n",
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-20 22:12:06,434]\u001b[0m Trial 10 finished with value: 0.7876275124551823 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.44}. Best is trial 10 with value: 0.7876275124551823.\u001b[0m\n",
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-20 22:12:27,899]\u001b[0m Trial 11 finished with value: 0.7845103931944603 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.9199999999999999}. Best is trial 10 with value: 0.7876275124551823.\u001b[0m\n",
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-20 22:12:45,105]\u001b[0m Trial 12 finished with value: 0.7860400200032461 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.66}. Best is trial 10 with value: 0.7876275124551823.\u001b[0m\n",
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-20 22:13:01,606]\u001b[0m Trial 13 finished with value: 0.7888674384634649 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.22}. Best is trial 13 with value: 0.7888674384634649.\u001b[0m\n",
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-20 22:13:24,727]\u001b[0m Trial 14 finished with value: 0.7807751575176376 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 1.81}. Best is trial 13 with value: 0.7888674384634649.\u001b[0m\n",
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-20 22:13:36,365]\u001b[0m Trial 15 finished with value: 0.7782904910213072 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 1.71}. Best is trial 13 with value: 0.7888674384634649.\u001b[0m\n",
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-20 22:13:51,762]\u001b[0m Trial 16 finished with value: 0.7876681770379126 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.2}. Best is trial 13 with value: 0.7888674384634649.\u001b[0m\n",
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-20 22:14:15,098]\u001b[0m Trial 17 finished with value: 0.7807751575176376 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 1.81}. Best is trial 13 with value: 0.7888674384634649.\u001b[0m\n",
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-20 22:14:27,888]\u001b[0m Trial 18 finished with value: 0.7781063789149262 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 1.32}. Best is trial 13 with value: 0.7888674384634649.\u001b[0m\n",
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-20 22:14:42,569]\u001b[0m Trial 19 finished with value: 0.7888674384634649 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.22}. Best is trial 13 with value: 0.7888674384634649.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 30s\n",
      "Wall time: 5min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "study = optuna.create_study(study_name=\"LogisticRegression\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_lr, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'penalty': 'l1', 'solver': 'saga', 'C': 0.22}\n",
      "f1_score на обучающем наборе: 0.79\n"
     ]
    }
   ],
   "source": [
    "#выводим результаты на обучающей выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тестовом наборе: 0.77\n",
      "f1_score на тестовом наборе: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#рассчитаем точность для тестовой выборки\n",
    "model = linear_model.LogisticRegression(**study.best_params,\n",
    "                                        random_state=42,\n",
    "                                        max_iter=50)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод. Grid Search работает существенно дольше остальных классов. За исключением Optuna с включенной кросс-валидацией.\n",
    "Оптимизация сильно зависит от того, как мы задаем параметры.\n",
    "Некорректное указание уровня силы регурялизации сильно искажает работу класса, \n",
    "так как он предлагает такие наилучшие параметры уровня силы регурялизации, которые не будут применимы на практике.\n",
    "По этой причине лучшее значение метрики f1 показал класс Random Search с уровнем силы регуляризации 0.1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оптимизация случайного леса"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем базовую модель и смотрим ее метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.00\n",
      "Test: 0.82\n"
     ]
    }
   ],
   "source": [
    "#Создаем объект класса случайный лес\n",
    "rf = ensemble.RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Обучаем модель\n",
    "rf.fit(X_train, y_train)\n",
    "#Выводим значения метрики \n",
    "y_train_pred = rf.predict(X_train)\n",
    "print('Train: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "y_test_pred = rf.predict(X_test)\n",
    "print('Test: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществляем оптимизацию модели с помощью класса Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.77 s\n",
      "Wall time: 9min 57s\n",
      "accuracy на тестовом наборе: 0.81\n",
      "f1_score на тестовом наборе: 0.82\n",
      "Наилучшие значения гиперпараметров: {'max_depth': 17, 'min_samples_leaf': 2, 'n_estimators': 140}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': list(range(10, 200, 10)), #количество деревьев\n",
    "              'min_samples_leaf': [2, 5], #минимум сэмплов для нового листа\n",
    "              'max_depth': list(np.linspace(10, 40, 5, dtype=int)) #максимальная глубина\n",
    "              }\n",
    "            \n",
    "grid_search_forest = GridSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5, #количество фолдов в кросс-валидации\n",
    "    n_jobs = -1\n",
    ")  \n",
    "\n",
    "%time grid_search_forest.fit(X_train, y_train) \n",
    "y_test_pred = grid_search_forest.predict(X_test)\n",
    "\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search_forest.score(X_test, y_test)))\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_forest.best_params_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Search**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществляем оптимизацию модели с помощью класса Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.72 s\n",
      "Wall time: 52.5 s\n",
      "accuracy на тестовом наборе: 0.81\n",
      "f1_score на тестовом наборе: 0.82\n",
      "Наилучшие значения гиперпараметров: {'n_estimators': 140, 'min_samples_leaf': 2, 'max_depth': 17}\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {'n_estimators': list(range(10, 200, 10)), #количество деревьев\n",
    "              'min_samples_leaf': [2, 5], #минимум сэмплов для нового листа\n",
    "              'max_depth': list(np.linspace(10, 40, 5, dtype=int)) #максимальная глубина\n",
    "              }\n",
    "            \n",
    "random_search_forest = RandomizedSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42), \n",
    "    param_distributions=param_distributions, \n",
    "    cv=5,\n",
    "    n_iter = 10, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time random_search_forest.fit(X_train, y_train) \n",
    "y_test_pred = random_search_forest.predict(X_test)\n",
    "\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(random_search_forest.score(X_test, y_test)))\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search_forest.best_params_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperopt**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществляем оптимизацию модели с помощью класса Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#зададим пространство поиска гиперпараметров\n",
    "space={'n_estimators': hp.quniform('n_estimators', 10, 200, 10), #количество деревьев\n",
    "       'max_depth' : hp.quniform('max_depth', 10, 40, 5), #максимальная глубина\n",
    "       'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 5, 1) #минимум сэмплов для нового листа\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=42):\n",
    "    #функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "              }\n",
    "  \n",
    "    #используем эту комбинацию для построения модели\n",
    "    model = ensemble.RandomForestClassifier(**params, random_state=42)\n",
    "\n",
    "    #обучаем модель с помощью кросс-валидации\n",
    "    model.fit(X, y)\n",
    "    score = cross_val_score(model, X, y, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:38<00:00,  4.95s/trial, best loss: -0.8196966149842488]\n",
      "Наилучшие значения гиперпараметров {'max_depth': 25.0, 'min_samples_leaf': 2.0, 'n_estimators': 150.0}\n",
      "CPU times: total: 34.3 s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# начинаем подбор гиперпараметров\n",
    "\n",
    "trials = Trials() #используется для логирования результатов\n",
    "\n",
    "best=fmin(hyperopt_rf, #наша функция \n",
    "          space=space, #пространство гиперпараметров\n",
    "          algo=tpe.suggest, #алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=20, #максимальное количество итераций\n",
    "          trials=trials, #логирование результатов\n",
    "          rstate=np.random.default_rng(random_state) #фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тестовом наборе: 0.81\n",
      "f1_score на тестовом наборе: 0.82\n"
     ]
    }
   ],
   "source": [
    "#рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(\n",
    "    random_state=42, \n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    max_depth=int(best['max_depth']),\n",
    "    min_samples_leaf=int(best['min_samples_leaf'])\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optuna**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществляем оптимизацию модели с помощью класса Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_rf(trial):\n",
    "  #задаем пространства поиска гиперпараметров\n",
    "  n_estimators = trial.suggest_int('n_estimators', 10, 200, 10) #количество деревьев\n",
    "  max_depth = trial.suggest_int('max_depth', 10, 40, 5) #максимальная глубина\n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 5, 1) #минимум сэмплов для нового листа\n",
    "\n",
    "  #создаем модель\n",
    "  model = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                          max_depth=max_depth,\n",
    "                                          min_samples_leaf=min_samples_leaf,\n",
    "                                          random_state=42)\n",
    "  #обучаем модель\n",
    "  model.fit(X_train, y_train)\n",
    "  score = cross_val_score(model, X, y, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-20 22:51:26,278]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:51:40,138]\u001b[0m Trial 0 finished with value: 0.8087178270867721 and parameters: {'n_estimators': 190, 'max_depth': 15, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.8087178270867721.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:51:48,043]\u001b[0m Trial 1 finished with value: 0.8107832005550011 and parameters: {'n_estimators': 120, 'max_depth': 25, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8107832005550011.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:51:52,730]\u001b[0m Trial 2 finished with value: 0.8075158599118974 and parameters: {'n_estimators': 80, 'max_depth': 30, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8107832005550011.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:51:56,236]\u001b[0m Trial 3 finished with value: 0.8077620071509506 and parameters: {'n_estimators': 50, 'max_depth': 40, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8107832005550011.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:52:06,542]\u001b[0m Trial 4 finished with value: 0.8127590534741186 and parameters: {'n_estimators': 170, 'max_depth': 15, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.8127590534741186.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:52:09,636]\u001b[0m Trial 5 finished with value: 0.8002537507284483 and parameters: {'n_estimators': 50, 'max_depth': 20, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.8127590534741186.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:52:12,730]\u001b[0m Trial 6 finished with value: 0.7963782106371082 and parameters: {'n_estimators': 60, 'max_depth': 10, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.8127590534741186.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:52:20,771]\u001b[0m Trial 7 finished with value: 0.8016961285699644 and parameters: {'n_estimators': 180, 'max_depth': 10, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.8127590534741186.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:52:29,879]\u001b[0m Trial 8 finished with value: 0.8060246964107887 and parameters: {'n_estimators': 180, 'max_depth': 35, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.8127590534741186.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:52:33,934]\u001b[0m Trial 9 finished with value: 0.808620832999536 and parameters: {'n_estimators': 60, 'max_depth': 20, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.8127590534741186.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:52:41,436]\u001b[0m Trial 10 finished with value: 0.8114151858769949 and parameters: {'n_estimators': 130, 'max_depth': 20, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.8127590534741186.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:52:49,534]\u001b[0m Trial 11 finished with value: 0.8114151858769949 and parameters: {'n_estimators': 130, 'max_depth': 20, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.8127590534741186.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:52:58,608]\u001b[0m Trial 12 finished with value: 0.8117000603676235 and parameters: {'n_estimators': 150, 'max_depth': 15, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.8127590534741186.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:53:00,613]\u001b[0m Trial 13 finished with value: 0.788698436682312 and parameters: {'n_estimators': 10, 'max_depth': 15, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.8127590534741186.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:53:09,771]\u001b[0m Trial 14 finished with value: 0.8117000603676235 and parameters: {'n_estimators': 150, 'max_depth': 15, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.8127590534741186.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:53:16,746]\u001b[0m Trial 15 finished with value: 0.8036759504295743 and parameters: {'n_estimators': 160, 'max_depth': 10, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.8127590534741186.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:53:28,759]\u001b[0m Trial 16 finished with value: 0.814555354072648 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.814555354072648.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:53:40,867]\u001b[0m Trial 17 finished with value: 0.8149257029862481 and parameters: {'n_estimators': 200, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.8149257029862481.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:53:52,829]\u001b[0m Trial 18 finished with value: 0.8149257029862481 and parameters: {'n_estimators': 200, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.8149257029862481.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 22:54:05,540]\u001b[0m Trial 19 finished with value: 0.8149257029862481 and parameters: {'n_estimators': 200, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.8149257029862481.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 48.2 s\n",
      "Wall time: 2min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#cоздаем объект исследования\n",
    "#можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
    "#ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_rf, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'n_estimators': 200, 'max_depth': 30, 'min_samples_leaf': 2}\n"
     ]
    }
   ],
   "source": [
    "#выводим результаты на обучающей выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тестовом наборе: 0.81\n",
      "f1_score на тестовом наборе: 0.82\n"
     ]
    }
   ],
   "source": [
    "#рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(**study.best_params, random_state=random_state)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы. Все классы показали себя одинаково с точки зрения итоговой полученной метрики f1.\n",
    "При этом класс Grid Search работал намного дольше остальных классов.\n",
    "Интересно, что все классы подобрали разные оптимальные параметры для модели, обеспечитив\n",
    "при этом одинаковый показатель метрики."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
